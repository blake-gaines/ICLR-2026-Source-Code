{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091e80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0305e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from experiments import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6db4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = {\n",
    "    \"CA Housing\": \"../experiments/california_housing_reg.pkl\",\n",
    "    \"CIFAR10\": \"../experiments/cifar10_cnn.pkl\",\n",
    "    \"MNIST\": \"../experiments/mnist_fc.pkl\",\n",
    "}\n",
    "split_layers = {\n",
    "    \"CIFAR10\": \"relu3\",\n",
    "    \"MNIST\": \"relu0\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2aa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = list()\n",
    "for name, path in exps.items():\n",
    "    row = dict()\n",
    "    e, row[\"Dataset Name\"] = Experiment.load(path), name\n",
    "    row[\"Experiment\"] = e\n",
    "    e.get_model(split_layer=None, root=\"..\")\n",
    "    # row[\"Full Model\"] = e.get_model(split_layer=None, root=\"..\")\n",
    "\n",
    "    train_dataset = e.train_dataset\n",
    "    test_dataset = e.test_dataset\n",
    "\n",
    "    # print(e.__dict__)\n",
    "    if hasattr(e, \"train_args\"):\n",
    "        e.train_kwargs = e.train_args\n",
    "    row[\"Learning Rate\"] = e.train_kwargs[\"lr\"]\n",
    "    row[\"Batch Size\"] = e.train_kwargs[\"batch_size\"] if \"batch_size\" in e.train_kwargs else 64\n",
    "    row[\"Epochs\"] = e.train_kwargs[\"epochs\"] if \"epochs\" in e.train_kwargs else 10\n",
    "\n",
    "    row[\"Dataset Size\"] = len(train_dataset) + len(test_dataset)\n",
    "\n",
    "    if train_dataset.task == \"classification\":\n",
    "        row[\"Task\"] = \"Classification\"\n",
    "        row[\"# Classes\"] = len(np.unique(train_dataset.y))\n",
    "        # row[\"Train Accuracy / $R^2$\"] = train_dataset.get_accuracy(e.model)\n",
    "        row[\"Test Accuracy\"] = test_dataset.get_accuracy(e.model)\n",
    "        row[\"Test AUC\"] = test_dataset.get_auc(e.model)\n",
    "        # row [\"Train AUC\"] = train_dataset.get_auc(e.model)\n",
    "    elif train_dataset.task == \"regression\":\n",
    "        row[\"Task\"] = \"Regression\"\n",
    "        # row[\"Train Accuracy / $R^2$\"] = train_dataset.get_rsquared(e.model)\n",
    "        row[\"Test $R^2$\"] = test_dataset.get_rsquared(e.model)\n",
    "        # row[\"Train AUC / MSE\"] = train_dataset.get_mse(e.model)\n",
    "        row[\"Test MSE\"] = test_dataset.get_mse(e.model)\n",
    "\n",
    "    if np.prod(e.model.input_shape) > 10:\n",
    "        embedder, model = e.get_model(split_layer=split_layers[name], root=\"..\")\n",
    "    else:\n",
    "        embedder, model = None, e.get_model(root=\"..\")\n",
    "    \n",
    "    \n",
    "    # row[\"Cut Model\"] = model\n",
    "    layers = list(model.layers.values())\n",
    "    widths = [layer.in_features for layer in layers if isinstance(layer, torch.nn.Linear)] + [layers[-1].out_features]\n",
    "    row[\"Hidden Layer Sizes\"] = ', '.join(str(w) for w in widths[1:-1])\n",
    "    row[\"Input Dimension\"] = widths[0]\n",
    "\n",
    "    df.append(row)\n",
    "df = pd.DataFrame(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ec356",
   "metadata": {},
   "outputs": [],
   "source": [
    "nice_df = df.set_index(\"Dataset Name\").T.fillna(\"NA\").loc[[\"Dataset Size\", \"Task\", \"# Classes\", \"Batch Size\", \"Epochs\", \"Learning Rate\", \"Input Dimension\", \"Hidden Layer Sizes\", \"Test Accuracy\", \"Test AUC\", \"Test $R^2$\", \"Test MSE\"]]\n",
    "nice_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdceadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../figures/\", exist_ok=True)\n",
    "with open(\"../figures/network_summary.tex\", \"w\") as f:\n",
    "    # f.write(df.set_index(\"Dataset Name\")[[\"Dataset Size\", \"Input Dimension\", \"Hidden Layer Sizes\", \"Accuracy / $R^2$\", \"AUC / MSE\"]].to_latex().replace(\"#\", \"\\\\#\").replace(\"%\", \"\\\\%\"))\n",
    "    f.write(nice_df.to_latex(float_format=\"%.2f\").replace(\"#\", \"\\\\#\").replace(\"%\", \"\\\\%\"))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
